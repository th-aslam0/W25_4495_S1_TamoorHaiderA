{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30920,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#pip install transformers datasets\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T07:26:06.055897Z","iopub.execute_input":"2025-03-09T07:26:06.056196Z","iopub.status.idle":"2025-03-09T07:26:06.062046Z","shell.execute_reply.started":"2025-03-09T07:26:06.056165Z","shell.execute_reply":"2025-03-09T07:26:06.061162Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#!pip install evaluate\n#!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T07:26:06.063041Z","iopub.execute_input":"2025-03-09T07:26:06.063319Z","iopub.status.idle":"2025-03-09T07:26:06.074183Z","shell.execute_reply.started":"2025-03-09T07:26:06.063297Z","shell.execute_reply":"2025-03-09T07:26:06.073260Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Install necessary libraries\n#!pip install transformers datasets\n\n# Import the required libraries\nfrom datasets import load_dataset\nfrom evaluate import load\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n\n# Load the dataset\ndataset = load_dataset('FreedomIntelligence/medical-o1-reasoning-SFT', 'en', split=\"train[:500]\", trust_remote_code=True)\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n\n# Preprocess function to format the data\ndef preprocess_function(examples):\n    # Combine the Question and Complex_CoT as the input\n    inputs = [f\"Question: {q} \\nComplex_CoT: {cot}\" for q, cot in zip(examples['Question'], examples['Complex_CoT'])]\n    targets = examples['Response']\n    \n    # Tokenize the inputs and targets\n    model_inputs = tokenizer(inputs, truncation=True, padding=True, max_length=512)\n    labels = tokenizer(targets, truncation=True, padding=True, max_length=512)\n\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T07:26:06.075373Z","iopub.execute_input":"2025-03-09T07:26:06.075583Z","execution_failed":"2025-03-09T07:26:28.463Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nWARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1741505170.423782     197 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:230\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Apply the preprocessing function to the dataset\ndataset = dataset.map(preprocess_function, batched=True)\n\n# Split the dataset into train and eval (90% train, 10% eval)\ntrain_dataset = dataset.shuffle(seed=42).select([i for i in range(int(0.9 * len(dataset)))])\neval_dataset = dataset.shuffle(seed=42).select([i for i in range(int(0.9 * len(dataset)), len(dataset))])\n\n# Load ROUGE metric for evaluation\nrouge_metric = load(\"rouge\")\n\n# Define evaluation function\ndef compute_metrics(pred):\n    labels_ids = pred.label_ids\n    preds = pred.predictions\n    decoded_preds = tokenizer.decode(preds[0], skip_special_tokens=True)\n    decoded_labels = tokenizer.decode(labels_ids[0], skip_special_tokens=True)\n    \n    result = rouge_metric.compute(predictions=[decoded_preds], references=[decoded_labels])\n    return result\n\n# Define the training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",          # output directory\n    evaluation_strategy=\"epoch\",     # Evaluate every epoch\n    num_train_epochs=3,              # number of training epochs\n    per_device_train_batch_size=8,   # batch size for training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir=\"./logs\",            # directory for storing logs\n)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-09T07:26:28.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the Trainer with the evaluation setup\ntrainer = Trainer(\n    model=model,                         # the model to train\n    args=training_args,                  # training arguments\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=eval_dataset,           # evaluation dataset\n    compute_metrics=compute_metrics,     # evaluation metrics (ROUGE)\n)\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-09T07:26:28.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start fine-tuning and evaluation\ntrainer.train()\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-09T07:26:28.466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model after training\nresults = trainer.evaluate()\nprint(results)\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-09T07:26:28.466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the fine-tuned model and tokenizer\nmodel.save_pretrained(\"fine_tuned_flan_t5\")\ntokenizer.save_pretrained(\"fine_tuned_flan_t5\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-09T07:26:28.466Z"}},"outputs":[],"execution_count":null}]}